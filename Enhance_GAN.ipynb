{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Enhance_GAN",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/au1206/Enhance-GAN/blob/master/Enhance_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMpDZAyLCaBx",
        "colab_type": "text"
      },
      "source": [
        "# Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOkF16FRmuC2",
        "colab_type": "text"
      },
      "source": [
        "The notebook revolves around the task of creating a GAN which takes in a degraded version of an image and generates a clean enhanced image.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "insnPyAeRC0x",
        "colab_type": "text"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoYMgagKCFdn",
        "colab_type": "text"
      },
      "source": [
        "## Intended Structure after Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCHJeTjnhj05",
        "colab_type": "text"
      },
      "source": [
        "Run the blocks in this section to get the following directory structure:\n",
        "```\n",
        "/content\n",
        "│\n",
        "└───pubfig831\n",
        "    │\n",
        "    └───correct\n",
        "    │   │\n",
        "    │   └───train\n",
        "    │   │   │\n",
        "    │   │   └───Adam Sandler\n",
        "    │   │   │   │   train__000001-000000.jpg\n",
        "    │   │   │   │   train__000001-000001.jpg\n",
        "    │   │   │   │   train__000001-000002.jpg\n",
        "    │   │   │   │   ...\n",
        "    │   │   │\n",
        "    │   │   └───Alec Baldwin\n",
        "    │   │   │   │   train__000002-000000.jpg\n",
        "    │   │   │   │   train__000002-000001.jpg\n",
        "    │   │   │   │   ...\n",
        "    │   │   │\n",
        "    │   │   └───Angelina Jolie\n",
        "    │   │   │   │   train__000003-000000.jpg\n",
        "    │   │   │   │   train__000003-000001.jpg\n",
        "    │   │   │   │   ...\n",
        "    │   │   │\n",
        "    │   │   │ ...\n",
        "    │   │\n",
        "    │   └───test\n",
        "    │       │\n",
        "    │       └───Adam Sandler\n",
        "    │       │   │   test__000001-000000.jpg\n",
        "    │       │   │   test__000001-000001.jpg\n",
        "    │       │   │   ...\n",
        "    │       │\n",
        "    │       └───Alec Baldwin\n",
        "    │       │   │   test__000002-000000.jpg\n",
        "    │       │   │   ...\n",
        "    │       │\n",
        "    │       └───Angelina Jolie\n",
        "    │       │   │   test__000003-000000.jpg\n",
        "    │       │   │   ...\n",
        "    │       │\n",
        "    │       │ ...\n",
        "    │\n",
        "    │\n",
        "    └───degraded\n",
        "        │   <Same directory structure as 'correct'>\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58tM3kFPNZ0Z",
        "colab_type": "text"
      },
      "source": [
        "Every image in the degraded directory is a degraded version of the image with the same name in the correct directory. e.g. `/content/pubfig831/degraded/Adam Sandler/train__000001-000002.jpg` is the degraded version of `/content/pubfig831/correct/Adam Sandler/train__000001-000002.jpg`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUrGJB04RF4d",
        "colab_type": "text"
      },
      "source": [
        "## Installation (pip etc)\n",
        "Add any other installation commands you want to in this block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3ljp1DHRNt7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bd642330-0ef6-417e-fadb-227a646dfd26"
      },
      "source": [
        "!pip install GPUtil\n",
        "!pip install tqdm\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: GPUtil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNJbKsnjR74d",
        "colab_type": "text"
      },
      "source": [
        "## Downloading and Generating Dataset\n",
        "This block downloads the data and applies the degrade function on the images to generate the dataset needed for training. The degrade function can be modified and tweaked to better represent the use case in hand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozoy8Olklwaj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "f5e8f0cb-23fa-442d-d58a-40da64356d26"
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def degrade(path: str) -> None:\n",
        "    \"\"\"Load image at `input_path`, distort and save as `output_path`\"\"\"\n",
        "    SHIFT = 2\n",
        "    image = cv2.imread(path)\n",
        "    to_swap = np.random.choice([False, True], image.shape[:2], p=[.8, .2])\n",
        "    swap_indices = np.where(to_swap[:-SHIFT] & ~to_swap[SHIFT:])\n",
        "    swap_vals = image[swap_indices[0] + SHIFT, swap_indices[1]]\n",
        "    image[swap_indices[0] + SHIFT, swap_indices[1]] = image[swap_indices]\n",
        "    image[swap_indices] = swap_vals\n",
        "    cv2.imwrite(path, image)\n",
        "\n",
        "!wget http://briancbecker.com/files/downloads/pubfig83lfw/pubfig83lfw_raw_in_dirs.zip\n",
        "!unzip -q pubfig83lfw_raw_in_dirs.zip\n",
        "!rm pubfig83lfw_raw_in_dirs.zip\n",
        "!mkdir pubfig831\n",
        "!mv pubfig83lfw_raw_in_dirs pubfig831/correct\n",
        "!rm -r pubfig831/correct/distract\n",
        "!cp -r pubfig831/correct pubfig831/degraded\n",
        "\n",
        "for image_path in tqdm(glob('pubfig831/degraded/*/*/*.jpg')):\n",
        "  degrade(image_path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-06 12:33:33--  http://briancbecker.com/files/downloads/pubfig83lfw/pubfig83lfw_raw_in_dirs.zip\n",
            "Resolving briancbecker.com (briancbecker.com)... 162.241.216.158\n",
            "Connecting to briancbecker.com (briancbecker.com)|162.241.216.158|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400247922 (382M) [application/zip]\n",
            "Saving to: ‘pubfig83lfw_raw_in_dirs.zip’\n",
            "\n",
            "pubfig83lfw_raw_in_ 100%[===================>] 381.71M  6.80MB/s    in 55s     \n",
            "\n",
            "2020-07-06 12:34:27 (6.99 MB/s) - ‘pubfig83lfw_raw_in_dirs.zip’ saved [400247922/400247922]\n",
            "\n",
            "mkdir: cannot create directory ‘pubfig831’: File exists\n",
            "rm: cannot remove 'pubfig831/correct/distract': No such file or directory\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 13002/13002 [01:00<00:00, 214.57it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz5BM22VralE",
        "colab_type": "text"
      },
      "source": [
        "# **Checking Free Memory**\n",
        "This block is just so that you can have an idea of the resources you have at hand on the Google Collab system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoMS9HMX6G9D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b9eaf35c-7af8-4873-872b-26c00854c252"
      },
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "gpu = GPU.getGPUs()[0]\n",
        "process = psutil.Process(os.getpid())\n",
        "print(f\"Gen RAM: Free {humanize.naturalsize(psutil.virtual_memory().available)} | Proc size {humanize.naturalsize(process.memory_info().rss)}\")\n",
        "print(f\"GPU RAM: Free {gpu.memoryFree:.0f}MB | Used {gpu.memoryUsed:.0f}MB | Util {gpu.memoryUtil*100:.0f}% | Total {gpu.memoryTotal:.0f}MB\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM: Free 26.3 GB | Proc size 182.4 MB\n",
            "GPU RAM: Free 16280MB | Used 0MB | Util 0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdDO74Z0HY3E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5cd26baf-d658-4c43-b1e5-2cbe117bc611"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMubMpKy15ac",
        "colab_type": "text"
      },
      "source": [
        "# **Main Code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIuewxbgsM4d",
        "colab_type": "text"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4DoUU8GYJes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "RESHAPE = (256,256)\n",
        "\n",
        "def load_image(path):\n",
        "    img = cv2.imread(path)\n",
        "    return img\n",
        "\n",
        "# converting input to (-1,1)\n",
        "def preprocess_image(cv_img):\n",
        "    cv_img = cv2.resize(cv_img,(RESHAPE))\n",
        "    img = np.array(cv_img)\n",
        "    img = (img - 127.5) / 127.5\n",
        "    return img\n",
        "\n",
        "\n",
        "def deprocess_image(img):\n",
        "    img = img * 127.5 + 127.5\n",
        "    return img.astype('uint8')\n",
        "\n",
        "\n",
        "def load_images(path, n_images):\n",
        "    if n_images < 0:\n",
        "        n_images = float(\"inf\")\n",
        "\n",
        "    all_A_paths = []\n",
        "    all_B_paths = []\n",
        "    all_A_paths_test = []\n",
        "    all_B_paths_test = []\n",
        "\n",
        "    for root, dire, files in os.walk(path):\n",
        "      for name in sorted(files):\n",
        "        filename = os.path.join(root,name)\n",
        "        if filename.split('/')[-3]==\"train\":\n",
        "          if filename.split('/')[-4]==\"degraded\":\n",
        "            all_B_paths.append(filename)\n",
        "          if filename.split('/')[-4]==\"correct\":\n",
        "            all_A_paths.append(filename)\n",
        "\n",
        "        if filename.split('/')[-3]==\"test\":\n",
        "          if filename.split('/')[-4]==\"degraded\":\n",
        "            all_B_paths_test.append(filename)\n",
        "          if filename.split('/')[-4]==\"correct\":\n",
        "            all_A_paths_test.append(filename)\n",
        "\n",
        "    images_A, images_B = [], []\n",
        "    images_A_paths, images_B_paths = [], []\n",
        "    images_A_test, images_B_test = [], []\n",
        "    images_A_paths_test, images_B_paths_test = [], []\n",
        "\n",
        "    for path_A, path_B in zip(all_A_paths, all_B_paths):\n",
        "        img_A, img_B = load_image(path_A), load_image(path_B)\n",
        "        images_A.append(preprocess_image(img_A))\n",
        "        images_B.append(preprocess_image(img_B))\n",
        "        images_A_paths.append(path_A)\n",
        "        images_B_paths.append(path_B)\n",
        "        if len(images_A) > n_images - 1: break\n",
        "\n",
        "    for path_A_test, path_B_test in zip(all_A_paths_test, all_B_paths_test):\n",
        "        img_A, img_B = load_image(path_A_test), load_image(path_B_test)\n",
        "        images_A_test.append(preprocess_image(img_A))\n",
        "        images_B_test.append(preprocess_image(img_B))\n",
        "        images_A_paths_test.append(path_A_test)\n",
        "        images_B_paths_test.append(path_B_test)\n",
        "        if len(images_A_test) > n_images - 1: break\n",
        "\n",
        "    return {\n",
        "        'A': np.array(images_A),\n",
        "        'A_paths': np.array(images_A_paths),\n",
        "        'A_test' : np.array(images_A_test),\n",
        "        'A_paths_test' : np.array(images_A_paths_test),\n",
        "        'B': np.array(images_B),\n",
        "        'B_paths': np.array(images_B_paths),\n",
        "        'B_test' : np.array(images_B_test),\n",
        "        'B_paths_test' : np.array(images_B_paths_test)\n",
        "    }\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSV-9eYyfbX2",
        "colab_type": "text"
      },
      "source": [
        "## Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqLOT8BUsAaW",
        "colab_type": "text"
      },
      "source": [
        "### **Constants and Hyperparemeters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8NNBxqO4qPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5aZVqBIDa7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bef41d00-eb70-40b1-edb4-17f42d4c273a"
      },
      "source": [
        "from keras.layers import Input, Conv2D, Activation, BatchNormalization\n",
        "from keras.layers.merge import Add\n",
        "from keras.layers.core import Dropout\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.engine import InputSpec\n",
        "from keras.engine.topology import Layer\n",
        "from keras.layers import Input, Conv2D, Activation, BatchNormalization\n",
        "from keras.layers.merge import Add\n",
        "from keras.utils import conv_utils\n",
        "from keras.layers.core import Dropout\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def res_block(input, filters, kernel_size=(3,3), strides=(1,1), use_dropout=False):\n",
        "\n",
        "    x = ReflectionPadding2D((1,1))(input)\n",
        "    x = Conv2D(filters=filters,\n",
        "               kernel_size=kernel_size,\n",
        "               strides=strides,)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    if use_dropout:\n",
        "        x = Dropout(0.5)(x)\n",
        "\n",
        "    x = ReflectionPadding2D((1,1))(x)\n",
        "    x = Conv2D(filters=filters,\n",
        "                kernel_size=kernel_size,\n",
        "                strides=strides,)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Two convolution layers followed by a direct connection between input and output\n",
        "    merged = Add()([input, x])\n",
        "    return merged\n",
        "\n",
        "\n",
        "# SOURCE for ReflectionPadding2D(Layer): https://github.com/cdiazbas/enhance/blob/master/models.py \n",
        "def spatial_reflection_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n",
        "    \"\"\"\n",
        "    Pad the 2nd and 3rd dimensions of a 4D tensor.\n",
        "\n",
        "    :param x: Input tensor\n",
        "    :param padding: Shape of padding to use\n",
        "    :param data_format: Tensorflow vs Theano convention ('channels_last', 'channels_first')\n",
        "    :return: Tensorflow tensor\n",
        "    \"\"\"\n",
        "    assert len(padding) == 2\n",
        "    assert len(padding[0]) == 2\n",
        "    assert len(padding[1]) == 2\n",
        "    if data_format is None:\n",
        "        data_format = image_data_format()\n",
        "    if data_format not in {'channels_first', 'channels_last'}:\n",
        "        raise ValueError('Unknown data_format ' + str(data_format))\n",
        "\n",
        "    if data_format == 'channels_first':\n",
        "        pattern = [[0, 0],\n",
        "                   [0, 0],\n",
        "                   list(padding[0]),\n",
        "                   list(padding[1])]\n",
        "    else:\n",
        "        pattern = [[0, 0],\n",
        "                   list(padding[0]), list(padding[1]),\n",
        "                   [0, 0]]\n",
        "    return tf.pad(x, pattern, \"REFLECT\")\n",
        "\n",
        "\n",
        "class ReflectionPadding2D(Layer):\n",
        "    \"\"\"Reflection-padding layer for 2D input (e.g. picture).\n",
        "    This layer can add rows and columns or zeros\n",
        "    at the top, bottom, left and right side of an image tensor.\n",
        "    # Arguments\n",
        "        padding: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n",
        "            - If int: the same symmetric padding\n",
        "                is applied to width and height.\n",
        "            - If tuple of 2 ints:\n",
        "                interpreted as two different\n",
        "                symmetric padding values for height and width:\n",
        "                `(symmetric_height_pad, symmetric_width_pad)`.\n",
        "            - If tuple of 2 tuples of 2 ints:\n",
        "                interpreted as\n",
        "                `((top_pad, bottom_pad), (left_pad, right_pad))`\n",
        "        data_format: A string,\n",
        "            one of `channels_last` (default) or `channels_first`.\n",
        "            The ordering of the dimensions in the inputs.\n",
        "            `channels_last` corresponds to inputs with shape\n",
        "            `(batch, height, width, channels)` while `channels_first`\n",
        "            corresponds to inputs with shape\n",
        "            `(batch, channels, height, width)`.\n",
        "            It defaults to the `image_data_format` value found in your\n",
        "            Keras config file at `~/.keras/keras.json`.\n",
        "            If you never set it, then it will be \"channels_last\".\n",
        "    # Input shape\n",
        "        4D tensor with shape:\n",
        "        - If `data_format` is `\"channels_last\"`:\n",
        "            `(batch, rows, cols, channels)`\n",
        "        - If `data_format` is `\"channels_first\"`:\n",
        "            `(batch, channels, rows, cols)`\n",
        "    # Output shape\n",
        "        4D tensor with shape:\n",
        "        - If `data_format` is `\"channels_last\"`:\n",
        "            `(batch, padded_rows, padded_cols, channels)`\n",
        "        - If `data_format` is `\"channels_first\"`:\n",
        "            `(batch, channels, padded_rows, padded_cols)`\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 padding=(1, 1),\n",
        "                 data_format=None,\n",
        "                 **kwargs):\n",
        "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
        "        self.data_format = K.normalize_data_format(data_format)\n",
        "        if isinstance(padding, int):\n",
        "            self.padding = ((padding, padding), (padding, padding))\n",
        "        elif hasattr(padding, '__len__'):\n",
        "            if len(padding) != 2:\n",
        "                raise ValueError('`padding` should have two elements. '\n",
        "                                 'Found: ' + str(padding))\n",
        "            height_padding = conv_utils.normalize_tuple(padding[0], 2,\n",
        "                                                        '1st entry of padding')\n",
        "            width_padding = conv_utils.normalize_tuple(padding[1], 2,\n",
        "                                                       '2nd entry of padding')\n",
        "            self.padding = (height_padding, width_padding)\n",
        "        else:\n",
        "            raise ValueError('`padding` should be either an int, '\n",
        "                             'a tuple of 2 ints '\n",
        "                             '(symmetric_height_pad, symmetric_width_pad), '\n",
        "                             'or a tuple of 2 tuples of 2 ints '\n",
        "                             '((top_pad, bottom_pad), (left_pad, right_pad)). '\n",
        "                             'Found: ' + str(padding))\n",
        "        self.input_spec = InputSpec(ndim=4)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            if input_shape[2] is not None:\n",
        "                rows = input_shape[2] + self.padding[0][0] + self.padding[0][1]\n",
        "            else:\n",
        "                rows = None\n",
        "            if input_shape[3] is not None:\n",
        "                cols = input_shape[3] + self.padding[1][0] + self.padding[1][1]\n",
        "            else:\n",
        "                cols = None\n",
        "            return (input_shape[0],\n",
        "                    input_shape[1],\n",
        "                    rows,\n",
        "                    cols)\n",
        "        elif self.data_format == 'channels_last':\n",
        "            if input_shape[1] is not None:\n",
        "                rows = input_shape[1] + self.padding[0][0] + self.padding[0][1]\n",
        "            else:\n",
        "                rows = None\n",
        "            if input_shape[2] is not None:\n",
        "                cols = input_shape[2] + self.padding[1][0] + self.padding[1][1]\n",
        "            else:\n",
        "                cols = None\n",
        "            return (input_shape[0],\n",
        "                    rows,\n",
        "                    cols,\n",
        "                    input_shape[3])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return spatial_reflection_2d_padding(inputs,\n",
        "                                             padding=self.padding,\n",
        "                                             data_format=self.data_format)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'padding': self.padding,\n",
        "                  'data_format': self.data_format}\n",
        "        base_config = super(ReflectionPadding2D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQr7M263s-CE",
        "colab_type": "text"
      },
      "source": [
        "### Generator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLjLc0INPJY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Activation, Add\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.core import Lambda\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "\n",
        "image_shape = (256, 256, 3)\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "input_nc = 3\n",
        "output_nc = 3\n",
        "input_shape_generator = (256, 256, input_nc)\n",
        "input_shape_discriminator = (256, 256, output_nc)\n",
        "n_blocks_gen = 9\n",
        "\n",
        "def generator_model():\n",
        "    # Architecture inspired by https://arxiv.org/pdf/1711.07064.pdf\n",
        "    # Current version : ResNet block\n",
        "    inputs = Input(shape=image_shape)\n",
        "\n",
        "    x = ReflectionPadding2D((3, 3))(inputs)\n",
        "    x = Conv2D(filters=ngf, kernel_size=(7,7), padding='valid')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Increase filter number, here 2 levels of downsampling\n",
        "    n_downsampling = 2\n",
        "    for i in range(n_downsampling):\n",
        "        mult = 2**i\n",
        "        x = Conv2D(filters=ngf*mult*2, kernel_size=(3,3), strides=2, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "    # 9 ResNet blocks\n",
        "    mult = 2**n_downsampling\n",
        "    for i in range(n_blocks_gen):\n",
        "        x = res_block(x, ngf*mult, use_dropout=True)\n",
        "\n",
        "    # final output after upsampling has 3 channels (RGB) \n",
        "    for i in range(n_downsampling):\n",
        "        mult = 2**(n_downsampling - i)\n",
        "        x = UpSampling2D(interpolation = 'bilinear')(x)\n",
        "        x = ReflectionPadding2D((1,1))(x)\n",
        "        x = Conv2D(filters = int(ngf * mult / 2),kernel_size=(3,3), strides=1, padding='valid')(x)\n",
        "        # x = Conv2DTranspose(filters=int(ngf * mult / 2), kernel_size=(3,3), strides=2, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "    x = ReflectionPadding2D((3,3))(x)\n",
        "    x = Conv2D(filters=output_nc, kernel_size=(7,7), padding='valid')(x)\n",
        "    x = Activation('tanh')(x)\n",
        "\n",
        "    # Add direct connection from input to output and recenter to [-1, 1]\n",
        "    outputs = Add()([x, inputs])\n",
        "    outputs = Lambda(lambda z: z/2)(outputs)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs, name='Gen')\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u7Eq3yltYld",
        "colab_type": "text"
      },
      "source": [
        "### Discriminator Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ6tsJqgi-Gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Activation, Add, UpSampling2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.core import Dense, Flatten, Lambda\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "def discriminator_model():\n",
        "    \n",
        "    n_layers, use_sigmoid = 3, False\n",
        "    inputs = Input(shape=input_shape_discriminator)\n",
        "\n",
        "    x = Conv2D(filters=ndf, kernel_size=(4, 4), strides=2, padding='same')(inputs)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    nf_mult, nf_mult_prev = 1, 1\n",
        "    for n in range(n_layers):\n",
        "        nf_mult_prev, nf_mult = nf_mult, min(2**n, 8)\n",
        "        x = Conv2D(filters=ndf*nf_mult, kernel_size=(4, 4), strides=2, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    nf_mult_prev, nf_mult = nf_mult, min(2**n_layers, 8)\n",
        "    x = Conv2D(filters=ndf*nf_mult, kernel_size=(4, 4), strides=1, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = Conv2D(filters=1, kernel_size=(4, 4), strides=1, padding='same')(x)\n",
        "    if use_sigmoid:\n",
        "        x = Activation('sigmoid')(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1024, activation='tanh')(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=x, name='Discriminator')\n",
        "    return model\n",
        "\n",
        "def generator_plus_discriminator(generator, discriminator):\n",
        "    inputs = Input(shape=image_shape)\n",
        "    generated_image = generator(inputs)\n",
        "    outputs = discriminator(generated_image)\n",
        "    model = Model(inputs=inputs, outputs=[generated_image, outputs])\n",
        "    return model\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bVjtttv0fKhp"
      },
      "source": [
        "### Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD0xLY_FfRRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend as K\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "def perceptual_loss(y_true, y_pred):\n",
        "    vgg = VGG16(include_top=False, weights='imagenet', input_shape=image_shape)\n",
        "    loss_model = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
        "    loss_model.trainable = False\n",
        "    return K.mean(K.square(loss_model(y_true) - loss_model(y_pred)))\n",
        "\n",
        "\n",
        "def wasserstein_loss(y_true, y_pred):\n",
        "    return K.mean(y_true*y_pred)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OHWHhltZfP2r"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhL1Myvmopcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.optimizers import Adam\n",
        "d_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "dg_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db_eANXWf52U",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCZ5YQ4uJbP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# handled in data loading"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huQiEB4sLP4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmcTD40OnmUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLaCJPsznmgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7msb0gPuC2A",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6Ccj64AtlK8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "e61b7bd2-23a1-492b-cbe3-25f80982b3ea"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import logging\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "if not os.path.exists('logs'):\n",
        "    os.makedirs('logs')\n",
        "logging.basicConfig(filename='logs/train_log.txt', level=logging.INFO)\n",
        "\n",
        "BASE_DIR = 'weights/'\n",
        "\n",
        "# saving weights with convention epochnumber in a directory created by datetime\n",
        "def save_all_weights(d, g, epoch_number, current_loss):\n",
        "    save_dir = BASE_DIR\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    g.save_weights(os.path.join(save_dir, 'generator_{}.h5'.format(epoch_number)), True)\n",
        "    d.save_weights(os.path.join(save_dir, 'discriminator_{}.h5'.format(epoch_number)), True)\n",
        "\n",
        "\n",
        "def train_multiple_outputs(n_images, batch_size, epoch_num, critic_updates=5):\n",
        "    data = load_images('/content/pubfig831/', n_images)\n",
        "    y_train, x_train = data['A'], data['B']\n",
        "\n",
        "    g = generator_model()\n",
        "    # logging.info(\"G created\")\n",
        "    d = discriminator_model()\n",
        "    # logging.info(\"D Created\")\n",
        "    dg = generator_plus_discriminator(g, d)\n",
        "\n",
        "    # d_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "    # dg_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "\n",
        "    d.trainable = True\n",
        "    d.compile(optimizer=d_opt, loss=wasserstein_loss)\n",
        "    # logging.info(\"D compiled\")\n",
        "    d.trainable = False\n",
        "    loss = [perceptual_loss, wasserstein_loss]\n",
        "    loss_weights = [100, 1]\n",
        "    dg.compile(optimizer=dg_opt, loss=loss, loss_weights=loss_weights)\n",
        "    # logging.info(\"DG compiled\")\n",
        "    d.trainable = True\n",
        "\n",
        "    output_true_batch, output_false_batch = np.ones((batch_size, 1)), -np.ones((batch_size, 1))\n",
        "\n",
        "    # log_path = './logs'\n",
        "    # tensorboard_callback = TensorBoard(log_path)\n",
        "\n",
        "    for epoch in tqdm.tqdm(range(epoch_num)):\n",
        "        permutated_indexes = np.random.permutation(x_train.shape[0])\n",
        "\n",
        "        d_losses = []\n",
        "        dg_losses = []\n",
        "        # logging.info(f\"x_train.shape : {x_train.shape}  y_train.shape : {y_train.shape}\")\n",
        "        for index in range(int(x_train.shape[0] / batch_size)):\n",
        "            batch_indexes = permutated_indexes[index*batch_size:(index+1)*batch_size]\n",
        "            image_degraded_batch = x_train[batch_indexes]\n",
        "            image_full_batch = y_train[batch_indexes]\n",
        "\n",
        "            generated_images = g.predict(x=image_degraded_batch, batch_size=batch_size)\n",
        "\n",
        "            for _ in range(critic_updates):\n",
        "                d_loss_real = d.train_on_batch(image_full_batch, output_true_batch)\n",
        "                d_loss_fake = d.train_on_batch(generated_images, output_false_batch)\n",
        "                d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "                d_losses.append(d_loss)\n",
        "\n",
        "            d.trainable = False\n",
        "\n",
        "            dg_loss = dg.train_on_batch(image_degraded_batch, [image_full_batch, output_true_batch])\n",
        "            dg_losses.append(dg_loss)\n",
        "\n",
        "            d.trainable = True\n",
        "        logging.info(f\"epoch:{epoch} d_loss:{np.mean(d_losses)} dg_loss{np.mean(dg_losses)}\")\n",
        "        print(f\"d_losses:{np.mean(d_losses)}, dg_losses:{np.mean(dg_losses)}\")\n",
        "        with open('log.txt', 'a+') as f:\n",
        "            f.write(f\"epoch:{epoch}, d_losses:{np.mean(d_losses)}, dg_losses:{np.mean(dg_losses)}\")\n",
        "\n",
        "        save_all_weights(d, g, epoch, int(np.mean(dg_losses)))\n",
        "\n",
        "\n",
        "\n",
        "# train_command()\n",
        "train_multiple_outputs(n_images=1024, batch_size=8, epoch_num=100, critic_updates=5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 1/100 [02:19<3:50:44, 139.85s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "d_losses:-0.4634945919860911, dg_losses:0.07828126102685928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 2/100 [04:20<3:39:11, 134.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "d_losses:-0.4798108358401805, dg_losses:0.047185253351926804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 3/100 [06:21<3:30:34, 130.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "d_losses:-0.4600009489338845, dg_losses:0.0758114606142044\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 4/100 [08:22<3:23:59, 127.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "d_losses:-0.3306058756525595, dg_losses:0.016490792855620384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 5/100 [10:24<3:18:50, 125.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "d_losses:9.818017918343875e-07, dg_losses:0.00017156224930658937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EloW4JAcyYDJ",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MYIV5m89BlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prediction and test code with some visualizations [ground truth, degraded, fixed]\n",
        "from PIL import Image\n",
        "from matplotlib.pyplot import plot, imshow\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "%matplotlib inline\n",
        "\n",
        "def test(batch_size):\n",
        "    data = load_images('/content/pubfig831/', batch_size)\n",
        "    y_test, x_test = data['A_test'], data['B_test']\n",
        "    g = generator_model()\n",
        "    g.load_weights('/content/weights/generator_80.h5')\n",
        "    # x_test = np.random.shuffle(x_test)\n",
        "    generated_images = g.predict(x=x_test, batch_size=batch_size)\n",
        "    generated = np.array([deprocess_image(img) for img in generated_images])\n",
        "    x_test = deprocess_image(x_test)\n",
        "    y_test = deprocess_image(y_test)\n",
        "    fig, axes = plt.subplots(5, 1, figsize=(16, 16), sharex=True, sharey=True)\n",
        "    ax = axes.ravel()\n",
        "\n",
        "    # show output\n",
        "    for i in range(generated_images.shape[0]):\n",
        "        y = y_test[i, :, :, ::-1]\n",
        "        x = x_test[i, :, :, ::-1]\n",
        "        img = generated[i, :, :, ::-1]\n",
        "        output = np.concatenate((y, x, img), axis=1)\n",
        "        im = Image.fromarray(output.astype(np.uint8))\n",
        "        im.save('results{}.png'.format(i))\n",
        "        ax[i].imshow(im)\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "test(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK1xPje9C7-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRuvBcUdd8t6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prediction for just 1 image and saving output as solo.png again using skimage formats\n",
        "from PIL import Image\n",
        "def test_img(test_path):\n",
        "  g = generator_model()\n",
        "  g.load_weights('/content/drive/My Drive/generator_60.h5')\n",
        "  img_test = load_image(test_path)\n",
        "  img_test = preprocess_image(img_test)\n",
        "  print(img_test.shape)\n",
        "  img_test = np.expand_dims(img_test, 0)\n",
        "  print(img_test.shape)\n",
        "  gen = g.predict(x=img_test, batch_size=1)\n",
        "\n",
        "  gen = np.array(deprocess_image(gen[0]))\n",
        "  print(gen.shape)\n",
        "  im = Image.fromarray(gen)\n",
        "  im.save('solo.png')\n",
        "\n",
        "\n",
        "test_img('/content/pubfig831/degraded/test/Adam Sandler/test__000001-000004.jpg')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNnCAsPZgyqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def fix(image: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    This function should take a degraded image in BGR format as a 250x250x3\n",
        "    numpy array with dtype np.uint8, and return its fixed version in the same format.\n",
        "\n",
        "    Make sure you don't return floating point values, or RGB instead of BGR, else the\n",
        "    image will look completely wrong when displayed.\n",
        "    \"\"\"\n",
        "    g = generator_model()\n",
        "    g.load_weights('/content/drive/My Drive/generator_60.h5')\n",
        "    img_test = preprocess_image(image)\n",
        "    img_test = np.expand_dims(img_test, 0)\n",
        "    gen = g.predict(img_test)\n",
        "    gen = np.array(deprocess_image(gen[0]))\n",
        "    gen = cv2.resize(gen,(250,250))\n",
        "    return gen\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZk4RFZhnpab",
        "colab_type": "text"
      },
      "source": [
        "# Results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwNZBH19xZSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qytD9XTM6mYI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akZdSIK8odKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import random\n",
        "from glob import glob\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "NUM_DISPLAY = 5\n",
        "\n",
        "files = glob('/content/pubfig831/correct/test/*/*')\n",
        "grid = []\n",
        "\n",
        "for path in random.sample(files, NUM_DISPLAY):\n",
        "  correct = cv2.imread(path)\n",
        "  split = path.split('/')\n",
        "  degraded = cv2.imread('/'.join([*split[:3], 'degraded', *split[4:]]))\n",
        "  fixed = fix(degraded)\n",
        "  grid.append(np.column_stack([degraded, fixed, correct]))\n",
        "\n",
        "image = np.row_stack(grid)\n",
        "dpi = float(plt.rcParams['figure.dpi'])\n",
        "figsize = image.shape[1] / dpi, image.shape[0] / dpi\n",
        "ax = plt.figure(figsize=figsize).add_axes([0, 0, 1, 1])\n",
        "ax.axis('off')\n",
        "ax.imshow(image[..., ::-1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gZiJGa3gghi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}